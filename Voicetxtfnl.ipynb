{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABd2Sv2gUWms",
        "outputId": "2314dd36-ed29-46f2-eb3b-b2c3f4446df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1UeFNeNppWNNsbp-2ZfwfWHgeOhtQalBX added_tokens.json\n",
            "Processing file 11C_wpxWmvaaaX--rut85tKGUa8pMvCjz config.json\n",
            "Processing file 1oP1MeEp5UfEOIraqvmeaweflPCucACRI generation_config.json\n",
            "Processing file 1wqhQ9oc_E4g49UsgFvn5DbVkQnyW993T merges.txt\n",
            "Processing file 1LQdIED_A8WH_0o5W-QmIChOWVrJ1R-Ia model.safetensors\n",
            "Processing file 1TGKaetXB3TCnciRL0Ig_EgTBv22LthEu normalizer.json\n",
            "Processing file 14RKL4Rm6OD3zjqFCxGD-wsDPoj9osWaS preprocessor_config.json\n",
            "Processing file 1iOYjc3u41zKk0SkcK4iigrXBL4aeTBut special_tokens_map.json\n",
            "Processing file 133gdidBz9W9slx0A8GayZxDAIn8yQMZ_ tokenizer_config.json\n",
            "Processing file 1hTUxudqwTIePwm9qT1R-J0_A4-Q8LpBG vocab.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UeFNeNppWNNsbp-2ZfwfWHgeOhtQalBX\n",
            "To: /content/my_data/added_tokens.json\n",
            "100%|██████████| 2.22k/2.22k [00:00<00:00, 3.33MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11C_wpxWmvaaaX--rut85tKGUa8pMvCjz\n",
            "To: /content/my_data/config.json\n",
            "100%|██████████| 1.33k/1.33k [00:00<00:00, 2.80MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oP1MeEp5UfEOIraqvmeaweflPCucACRI\n",
            "To: /content/my_data/generation_config.json\n",
            "100%|██████████| 290/290 [00:00<00:00, 447kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wqhQ9oc_E4g49UsgFvn5DbVkQnyW993T\n",
            "To: /content/my_data/merges.txt\n",
            "100%|██████████| 544k/544k [00:00<00:00, 85.8MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LQdIED_A8WH_0o5W-QmIChOWVrJ1R-Ia\n",
            "From (redirected): https://drive.google.com/uc?id=1LQdIED_A8WH_0o5W-QmIChOWVrJ1R-Ia&confirm=t&uuid=1d8c6721-1711-4117-a50a-62d9fb0c3ef0\n",
            "To: /content/my_data/model.safetensors\n",
            "100%|██████████| 290M/290M [00:05<00:00, 57.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TGKaetXB3TCnciRL0Ig_EgTBv22LthEu\n",
            "To: /content/my_data/normalizer.json\n",
            "100%|██████████| 54.4k/54.4k [00:00<00:00, 41.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14RKL4Rm6OD3zjqFCxGD-wsDPoj9osWaS\n",
            "To: /content/my_data/preprocessor_config.json\n",
            "100%|██████████| 353/353 [00:00<00:00, 956kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iOYjc3u41zKk0SkcK4iigrXBL4aeTBut\n",
            "To: /content/my_data/special_tokens_map.json\n",
            "100%|██████████| 2.32k/2.32k [00:00<00:00, 5.96MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=133gdidBz9W9slx0A8GayZxDAIn8yQMZ_\n",
            "To: /content/my_data/tokenizer_config.json\n",
            "100%|██████████| 21.5k/21.5k [00:00<00:00, 19.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hTUxudqwTIePwm9qT1R-J0_A4-Q8LpBG\n",
            "To: /content/my_data/vocab.json\n",
            "100%|██████████| 1.09M/1.09M [00:00<00:00, 105MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['preprocessor_config.json', 'tokenizer_config.json', 'model.safetensors', 'special_tokens_map.json', 'generation_config.json', 'normalizer.json', 'config.json', 'merges.txt', 'vocab.json', 'added_tokens.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "# Install gdown\n",
        "!pip install gdown\n",
        "\n",
        "# Import gdown\n",
        "import gdown\n",
        "\n",
        "# Folder ID\n",
        "folder_id = '1i9mph0-by_Rm2J8iKtx9Hf-iaDJvMETU'\n",
        "\n",
        "# Download the folder\n",
        "gdown.download_folder(f'https://drive.google.com/drive/folders/{folder_id}', output='/content/my_data')\n",
        "\n",
        "# List files in the downloaded folder\n",
        "import os\n",
        "folder_path = '/content/my_data'\n",
        "print(os.listdir(folder_path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "\n",
        "# Paths\n",
        "model_path = \"/content/my_data\"\n",
        "audio_path = \"/content/33.mp3\"\n",
        "\n",
        "# Load model and processor\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_path).to(\"cpu\")\n",
        "\n",
        "# Load and preprocess audio\n",
        "speech_array, sampling_rate = torchaudio.load(audio_path)\n",
        "if sampling_rate != 16000:\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
        "    speech_array = resampler(speech_array)\n",
        "\n",
        "# Mono channel expected\n",
        "if speech_array.shape[0] > 1:\n",
        "    speech_array = speech_array.mean(dim=0, keepdim=True)\n",
        "\n",
        "# Remove channel dimension\n",
        "input_features = processor.feature_extractor(speech_array.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_features\n",
        "\n",
        "# Generate\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(input_features)\n",
        "\n",
        "# Decode\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(\"📝 Transcribed Text:\", transcription)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_E1QpSxYeNu",
        "outputId": "2028019a-e284-4171-ee45-698e79de342d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Transcribed Text: إِنَّ اللَّهَ لَا يَسْتَحْيِي أَنْ يَضْرِبَ مَثَلًا مَا بَعُوضَةً فَمَا فَوْقَهَا فَأَمَّا الَّذِينَ آمَنُوا فَيَعْلَمُونَ أَنَّهُ الْحَقُّ مِنْ رَبِّهِمْ وَأَمَّا الَّذِينَ كَفَرُوا فَيَقُولُونَ مَاذَا أَرَادَ اللَّهُ بِهَذَا مَثَلًا\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-ngrok torchaudio transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv-4VkIWcBWO",
        "outputId": "de9fbd64-e72c-41e4-8359-3d54f2bcd8d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "import os\n",
        "\n",
        "# Setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "# 🔥 Load model and processor once\n",
        "MODEL_PATH = \"/content/my_data\"  # Your model folder path\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(MODEL_PATH).to(\"cpu\")\n",
        "\n",
        "# 🎙️ Function to transcribe audio\n",
        "def transcribe_audio(audio_path):\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "    # Convert stereo to mono if needed\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # Resample if not 16kHz\n",
        "    if sample_rate != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "        waveform = resampler(waveform)\n",
        "\n",
        "    input_features = processor.feature_extractor(\n",
        "        waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\"\n",
        "    ).input_features\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(input_features)\n",
        "\n",
        "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return transcription\n",
        "\n",
        "# 🔥 Flask endpoint\n",
        "@app.route('/transcribe', methods=['POST'])\n",
        "def transcribe():\n",
        "    if 'audio' not in request.files:\n",
        "        return jsonify({'error': 'No audio file uploaded'}), 400\n",
        "\n",
        "    audio_file = request.files['audio']\n",
        "    file_path = os.path.join(\"/content\", audio_file.filename)\n",
        "    audio_file.save(file_path)\n",
        "\n",
        "    try:\n",
        "        text = transcribe_audio(file_path)\n",
        "        return jsonify({'transcription': text})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "    finally:\n",
        "        os.remove(file_path)\n",
        "\n",
        "# Set your ngrok authtoken here\n",
        "# Replace \"YOUR_AUTHTOKEN\" with the actual token from your ngrok dashboard\n",
        "ngrok.set_auth_token(\"2wwoXpT4cJkm5oFI6tbeH3zYJPR_871PxxvpSbr1aXdwxGY3e\")\n",
        "\n",
        "# 🚀 Start the API and ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"🚀 Your public ngrok URL:\", public_url)\n",
        "\n",
        "# 🔥 Run Flask\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBXRsFkXcBSv",
        "outputId": "e34f7188-8bc5-4e7e-dcd1-c2b9e7bf94ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "🚀 Your public ngrok URL: NgrokTunnel: \"https://e975-35-233-211-24.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:11:33] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:11:33] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:15:12] \"POST /transcribe HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:15:55] \"POST /transcribe HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:19:29] \"POST /transcribe HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:20:49] \"POST /transcribe HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [21/May/2025 20:21:49] \"\u001b[33mGET /transcribe' HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, TFAutoModelForSpeechSeq2Seq\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the model and processor\n",
        "model_path = \"/content/my_data\"  # Path to your model directory\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_path)\n",
        "\n",
        "# Convert PyTorch model to TensorFlow\n",
        "tf_model = TFAutoModelForSpeechSeq2Seq.from_pretrained(model_path, from_pt=True)\n",
        "\n",
        "# Save the TensorFlow model\n",
        "tf_model.save(\"tf_model\", save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPpYPEnEV8pq",
        "outputId": "3ecc3ff0-c549-4ba0-bceb-d3ce0d820c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFWhisperForConditionalGeneration.\n",
            "\n",
            "All the weights of TFWhisperForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWhisperForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TensorFlow model\n",
        "tf_model = tf.saved_model.load(\"tf_model\")\n",
        "\n",
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_model\")\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS  # Needed for transformer ops\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "soDGY9cSV8mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Quantization to reduce size\n",
        "tflite_model = converter.convert()\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "WX9rfTdKXNg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "import librosa\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "# Load the processor for tokenization/decoding\n",
        "model_path = \"/content/my_data\"\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "\n",
        "# Load Arabic audio (16 kHz, mono)\n",
        "audio_path = \"/content/001 Al-Fatihah alfath.wav\"  # Replace with your Arabic WAV file\n",
        "audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "\n",
        "# Whisper expects 30-second chunks; pad or truncate\n",
        "max_length = 30 * 16000  # 30 seconds at 16 kHz\n",
        "if len(audio) > max_length:\n",
        "    audio = audio[:max_length]\n",
        "else:\n",
        "    audio = np.pad(audio, (0, max_length - len(audio)), mode=\"constant\")\n",
        "\n",
        "# Normalize audio to [-1, 1]\n",
        "audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "# Prepare audio input (shape: [1, 480000])\n",
        "audio_input = audio.reshape(1, -1).astype(np.float32)\n",
        "\n",
        "# Load TFLite model\n",
        "interpreter = tflite.Interpreter(model_path=\"/content/model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input/output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Print all input details to identify the correct tensors\n",
        "print(\"All Input Details:\")\n",
        "for i, detail in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Name: {detail['name']}\")\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "print(\"\\nOutput Details:\")\n",
        "for detail in output_details:\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "# Prepare inputs (based on the error, we need to handle multiple inputs)\n",
        "decoder_input_ids = np.array([[50258]], dtype=np.int32)  # Start token for Whisper\n",
        "transcription_ids = []\n",
        "\n",
        "# Autoregressive decoding loop\n",
        "max_output_length = 448  # Max transcription length\n",
        "for _ in range(max_output_length):\n",
        "    # Update attention mask to match the current sequence length\n",
        "    attention_mask = np.ones((1, decoder_input_ids.shape[1]), dtype=np.int32)\n",
        "\n",
        "    # Set inputs\n",
        "    for detail in input_details:\n",
        "        if \"input_features\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], audio_input)\n",
        "        elif \"attention_mask\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], attention_mask)\n",
        "        elif \"input_ids\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], decoder_input_ids)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "    # Get the predicted token\n",
        "    predicted_token = np.argmax(output_data[0, -1, :])  # Last token\n",
        "    transcription_ids.append(predicted_token)\n",
        "\n",
        "    # Stop if end token is generated\n",
        "    if predicted_token == 50256:  # Whisper end token\n",
        "        break\n",
        "\n",
        "    # Append predicted token for the next iteration\n",
        "    decoder_input_ids = np.append(decoder_input_ids, [[predicted_token]], axis=1)\n",
        "\n",
        "# Decode the token IDs to Arabic text\n",
        "transcription = processor.batch_decode([transcription_ids])[0]\n",
        "print(\"Arabic Transcription:\", transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "nLoIWJ1jXoel",
        "outputId": "aba0362e-4d5c-4183-d2e1-1701f24730e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Input Details:\n",
            "Input 0:\n",
            "  Name: serving_default_decoder_attention_mask:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 1:\n",
            "  Name: serving_default_decoder_input_ids:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 2:\n",
            "  Name: serving_default_input_features:0\n",
            "  Shape: [ 1 80  1]\n",
            "  Type: <class 'numpy.float32'>\n",
            "\n",
            "Output Details:\n",
            "  Shape: [    1     1 51865]\n",
            "  Type: <class 'numpy.float32'>\n",
            "  Shape: [   1 1500  512]\n",
            "  Type: <class 'numpy.float32'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot set tensor: Dimension mismatch. Got 2 but expected 3 for input 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e08c5145f7ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdetail\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_details\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"input_features\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    742\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \"\"\"\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 2 but expected 3 for input 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "import librosa\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "# Load the processor for tokenization and feature extraction\n",
        "model_path = \"/content/my_data\"  # Path to your model directory\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "\n",
        "# Load Arabic audio (16 kHz, mono)\n",
        "audio_path = \"/content/001 Al-Fatihah alfath.wav\"  # Replace with your Arabic WAV file\n",
        "audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "\n",
        "# Whisper expects 30-second chunks; pad or truncate\n",
        "max_length = 30 * 16000  # 30 seconds at 16 kHz\n",
        "if len(audio) > max_length:\n",
        "    audio = audio[:max_length]\n",
        "else:\n",
        "    audio = np.pad(audio, (0, max_length - len(audio)), mode=\"constant\")\n",
        "\n",
        "# Normalize audio to [-1, 1]\n",
        "audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "# Convert audio to log-Mel spectrogram features using the processor\n",
        "# Whisper expects features of shape [1, 80, 3000] typically, but TFLite model expects [1, 80, 1]\n",
        "inputs = processor(audio, sampling_rate=16000, return_tensors=\"np\")\n",
        "audio_input = inputs[\"input_features\"]  # Shape: [1, 80, 3000]\n",
        "\n",
        "# Since the TFLite model expects [1, 80, 1], we need to adjust (this may indicate a conversion issue)\n",
        "# For now, let's take a slice or average to match the expected shape\n",
        "audio_input = audio_input[:, :, :1]  # Take first time step: [1, 80, 1]\n",
        "\n",
        "# Load TFLite model\n",
        "interpreter = tflite.Interpreter(model_path=\"/content/model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input/output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Print all input details\n",
        "print(\"All Input Details:\")\n",
        "for i, detail in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Name: {detail['name']}\")\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "print(\"\\nOutput Details:\")\n",
        "for detail in output_details:\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "# Prepare inputs\n",
        "decoder_input_ids = np.array([[50258]], dtype=np.int32)  # Start token for Whisper\n",
        "transcription_ids = []\n",
        "\n",
        "# Autoregressive decoding loop\n",
        "max_output_length = 448  # Max transcription length\n",
        "for _ in range(max_output_length):\n",
        "    # Update attention mask to match the current sequence length\n",
        "    attention_mask = np.ones((1, decoder_input_ids.shape[1]), dtype=np.int32)\n",
        "\n",
        "    # Set inputs\n",
        "    for detail in input_details:\n",
        "        if \"input_features\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], audio_input)\n",
        "        elif \"attention_mask\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], attention_mask)\n",
        "        elif \"input_ids\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], decoder_input_ids)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "    # Get the predicted token\n",
        "    predicted_token = np.argmax(output_data[0, -1, :])  # Last token\n",
        "    transcription_ids.append(predicted_token)\n",
        "\n",
        "    # Stop if end token is generated\n",
        "    if predicted_token == 50256:  # Whisper end token\n",
        "        break\n",
        "\n",
        "    # Append predicted token for the next iteration\n",
        "    decoder_input_ids = np.append(decoder_input_ids, [[predicted_token]], axis=1)\n",
        "\n",
        "# Decode the token IDs to Arabic text\n",
        "transcription = processor.batch_decode([transcription_ids])[0]\n",
        "print(\"Arabic Transcription:\", transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "gshQaRLWbqDi",
        "outputId": "28ae5b68-a654-492a-c98f-0d40c506258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Input Details:\n",
            "Input 0:\n",
            "  Name: serving_default_decoder_attention_mask:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 1:\n",
            "  Name: serving_default_decoder_input_ids:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 2:\n",
            "  Name: serving_default_input_features:0\n",
            "  Shape: [ 1 80  1]\n",
            "  Type: <class 'numpy.float32'>\n",
            "\n",
            "Output Details:\n",
            "  Shape: [    1     1 51865]\n",
            "  Type: <class 'numpy.float32'>\n",
            "  Shape: [   1 1500  512]\n",
            "  Type: <class 'numpy.float32'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot set tensor: Dimension mismatch. Got 2 but expected 1 for dimension 1 of input 0.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6c77f8a74c54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    742\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \"\"\"\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 2 but expected 1 for dimension 1 of input 0."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, TFAutoModelForSpeechSeq2Seq\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the model and processor\n",
        "model_path = \"my_model\"  # Replace with your local model directory\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_path)\n",
        "\n",
        "# Convert to TensorFlow\n",
        "tf_model = TFAutoModelForSpeechSeq2Seq.from_pretrained(model_path, from_pt=True)\n",
        "\n",
        "# Create a concrete function with dynamic shapes\n",
        "@tf.function(input_signature=[\n",
        "    tf.TensorSpec([1, 80, 3000], tf.float32, name=\"input_features\"),\n",
        "    tf.TensorSpec([1, None], tf.int32, name=\"decoder_input_ids\"),\n",
        "    tf.TensorSpec([1, None], tf.int32, name=\"decoder_attention_mask\"),\n",
        "])\n",
        "def serving_fn(input_features, decoder_input_ids, decoder_attention_mask):\n",
        "    return tf_model(\n",
        "        input_features=input_features,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        attention_mask=decoder_attention_mask,\n",
        "        training=False\n",
        "    )\n",
        "\n",
        "# Save the model with the signature\n",
        "tf.saved_model.save(tf_model, \"tf_model\", signatures={\"serving_default\": serving_fn})\n",
        "\n",
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_model\")\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.allow_custom_ops = True\n",
        "converter.experimental_enable_dynamic_shapes = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"arabic_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "CbmWqH62e4ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, TFAutoModelForSpeechSeq2Seq\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the model and processor\n",
        "model_path = \"/content/my_data\"  # Replace with your local model directory\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_path)\n",
        "\n",
        "# Convert to TensorFlow\n",
        "tf_model = TFAutoModelForSpeechSeq2Seq.from_pretrained(model_path, from_pt=True)\n",
        "\n",
        "# Create a concrete function with dynamic shapes for decoder_input_ids\n",
        "@tf.function(input_signature=[\n",
        "    tf.TensorSpec([1, 80, 3000], tf.float32, name=\"input_features\"),\n",
        "    tf.TensorSpec([1, None], tf.int32, name=\"decoder_input_ids\"),\n",
        "])\n",
        "def serving_fn(input_features, decoder_input_ids):\n",
        "    return tf_model(\n",
        "        input_features=input_features,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        training=False\n",
        "    )\n",
        "\n",
        "# Save the model with the signature\n",
        "tf.saved_model.save(tf_model, \"tf_modell\", signatures={\"serving_default\": serving_fn})\n",
        "\n",
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_model\")\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.allow_custom_ops = True\n",
        "converter.experimental_enable_dynamic_shapes = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"arabic_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3bfzbaVfpt3",
        "outputId": "af31dea8-0251-42e3-9541-2ec0c02a97cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFWhisperForConditionalGeneration.\n",
            "\n",
            "All the weights of TFWhisperForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWhisperForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, TFAutoModelForSpeechSeq2Seq\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the model and processor\n",
        "model_path = \"/content/my_data\"  # Replace with your local model directory\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_path)\n",
        "\n",
        "# Convert to TensorFlow\n",
        "tf_model = TFAutoModelForSpeechSeq2Seq.from_pretrained(model_path, from_pt=True)\n",
        "\n",
        "# Create a concrete function with the correct input shape for Whisper\n",
        "@tf.function(input_signature=[\n",
        "    tf.TensorSpec([1, 80, 3000], tf.float32, name=\"input_features\"),\n",
        "    tf.TensorSpec([1, None], tf.int32, name=\"decoder_input_ids\"),\n",
        "])\n",
        "def serving_fn(input_features, decoder_input_ids):\n",
        "    return tf_model(\n",
        "        input_features=input_features,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        training=False\n",
        "    )\n",
        "\n",
        "# Save the model with the signature\n",
        "tf.saved_model.save(tf_model, \"tf_model\", signatures={\"serving_default\": serving_fn})\n",
        "\n",
        "# Convert to TFLite with the correct shape\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_model\")\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.allow_custom_ops = True\n",
        "converter.experimental_enable_dynamic_shapes = True\n",
        "\n",
        "# Explicitly set input shapes to ensure correctness\n",
        "converter.inference_input_type = tf.float32\n",
        "converter.inference_output_type = tf.float32\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"arabic_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Verify the TFLite model shapes\n",
        "interpreter = tflite.Interpreter(model_path=\"arabic_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"All Input Details:\")\n",
        "for i, detail in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Name: {detail['name']}\")\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "print(\"\\nOutput Details:\")\n",
        "for detail in output_details:\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWeW0o_xgwsD",
        "outputId": "3c66d350-c6a0-4b86-8af0-82e4637e0168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFWhisperForConditionalGeneration.\n",
            "\n",
            "All the weights of TFWhisperForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWhisperForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Input Details:\n",
            "Input 0:\n",
            "  Name: serving_default_decoder_input_ids:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 1:\n",
            "  Name: serving_default_input_features:0\n",
            "  Shape: [   1   80 3000]\n",
            "  Type: <class 'numpy.float32'>\n",
            "\n",
            "Output Details:\n",
            "  Shape: [    1     1 51865]\n",
            "  Type: <class 'numpy.float32'>\n",
            "  Shape: [   1 1500  512]\n",
            "  Type: <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "import librosa\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "model_path = \"/content/my_data\"\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "\n",
        "audio_path = \"/content/001 Al-Fatihah alfath.wav\"\n",
        "audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "\n",
        "max_length = 30 * 16000\n",
        "if len(audio) > max_length:\n",
        "    audio = audio[:max_length]\n",
        "else:\n",
        "    audio = np.pad(audio, (0, max_length - len(audio)), mode=\"constant\")\n",
        "\n",
        "audio = audio / np.max(np.abs(audio))\n",
        "inputs = processor(audio, sampling_rate=16000, return_tensors=\"np\")\n",
        "audio_input = inputs[\"input_features\"]  # Shape: [1, 80, 3000]\n",
        "\n",
        "interpreter = tflite.Interpreter(model_path=\"arabic_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"All Input Details:\")\n",
        "for i, detail in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Name: {detail['name']}\")\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "print(\"\\nOutput Details:\")\n",
        "for detail in output_details:\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "decoder_input_ids = np.array([[50258]], dtype=np.int32)  # Explicitly set to INT32\n",
        "transcription_ids = []\n",
        "\n",
        "max_output_length = 448\n",
        "for step in range(max_output_length):\n",
        "    current_length = decoder_input_ids.shape[1]\n",
        "\n",
        "    for i, detail in enumerate(input_details):\n",
        "        if \"decoder_input_ids\" in detail[\"name\"]:\n",
        "            interpreter.resize_tensor_input(i, [1, current_length])\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Debug: Print the type of decoder_input_ids\n",
        "    print(f\"Setting decoder_input_ids with shape: {decoder_input_ids.shape}, type: {decoder_input_ids.dtype}\")\n",
        "\n",
        "    for detail in input_details:\n",
        "        if \"input_features\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], audio_input)\n",
        "        elif \"decoder_input_ids\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], decoder_input_ids.astype(np.int32))  # Explicit cast\n",
        "\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "    predicted_token = np.argmax(output_data[0, -1, :])\n",
        "    transcription_ids.append(predicted_token)\n",
        "\n",
        "    if predicted_token == 50256:\n",
        "        break\n",
        "\n",
        "    decoder_input_ids = np.append(decoder_input_ids, [[predicted_token]], dtype=np.int32)\n",
        "\n",
        "transcription = processor.batch_decode([transcription_ids], skip_special_tokens=True)[0]\n",
        "print(\"Arabic Transcription:\", transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "zGERhHdSjUwc",
        "outputId": "aa0c5745-28b9-4472-eb44-b9e0162f5df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Input Details:\n",
            "Input 0:\n",
            "  Name: serving_default_decoder_input_ids:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 1:\n",
            "  Name: serving_default_input_features:0\n",
            "  Shape: [   1   80 3000]\n",
            "  Type: <class 'numpy.float32'>\n",
            "\n",
            "Output Details:\n",
            "  Shape: [    1     1 51865]\n",
            "  Type: <class 'numpy.float32'>\n",
            "  Shape: [   1 1500  512]\n",
            "  Type: <class 'numpy.float32'>\n",
            "Setting decoder_input_ids with shape: (1, 1), type: int32\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "append() got an unexpected keyword argument 'dtype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f7066f5c4454>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mdecoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtranscription_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: append() got an unexpected keyword argument 'dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "import librosa\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "model_path = \"/content/my_data\"\n",
        "processor = AutoProcessor.from_pretrained(model_path)\n",
        "\n",
        "audio_path = \"/content/001 Al-Fatihah alfath.wav\"\n",
        "audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "\n",
        "max_length = 30 * 16000\n",
        "if len(audio) > max_length:\n",
        "    audio = audio[:max_length]\n",
        "else:\n",
        "    audio = np.pad(audio, (0, max_length - len(audio)), mode=\"constant\")\n",
        "\n",
        "audio = audio / np.max(np.abs(audio))\n",
        "inputs = processor(audio, sampling_rate=16000, return_tensors=\"np\")\n",
        "audio_input = inputs[\"input_features\"]  # Shape: [1, 80, 3000]\n",
        "\n",
        "interpreter = tflite.Interpreter(model_path=\"/content/arabic_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"All Input Details:\")\n",
        "for i, detail in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Name: {detail['name']}\")\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "print(\"\\nOutput Details:\")\n",
        "for detail in output_details:\n",
        "    print(f\"  Shape: {detail['shape']}\")\n",
        "    print(f\"  Type: {detail['dtype']}\")\n",
        "\n",
        "decoder_input_ids = np.array([[50258]], dtype=np.int32)\n",
        "transcription_ids = []\n",
        "\n",
        "max_output_length = 448\n",
        "for step in range(max_output_length):\n",
        "    current_length = decoder_input_ids.shape[1]\n",
        "\n",
        "    for i, detail in enumerate(input_details):\n",
        "        if \"decoder_input_ids\" in detail[\"name\"]:\n",
        "            interpreter.resize_tensor_input(i, [1, current_length])\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    print(f\"Setting decoder_input_ids with shape: {decoder_input_ids.shape}, type: {decoder_input_ids.dtype}\")\n",
        "\n",
        "    for detail in input_details:\n",
        "        if \"input_features\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], audio_input)\n",
        "        elif \"decoder_input_ids\" in detail[\"name\"]:\n",
        "            interpreter.set_tensor(detail[\"index\"], decoder_input_ids)\n",
        "\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "\n",
        "    predicted_token = np.argmax(output_data[0, -1, :])\n",
        "    transcription_ids.append(predicted_token)\n",
        "\n",
        "    if predicted_token == 50256:\n",
        "        break\n",
        "\n",
        "    # Fix: Convert predicted_token to np.int32 and append correctly\n",
        "    new_token = np.array([[predicted_token]], dtype=np.int32)\n",
        "    decoder_input_ids = np.concatenate((decoder_input_ids, new_token), axis=1)\n",
        "\n",
        "transcription = processor.batch_decode([transcription_ids], skip_special_tokens=True)[0]\n",
        "print(\"Arabic Transcription:\", transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJDguRJekiXs",
        "outputId": "fecca965-a38b-4a97-a3c9-54eaaf14a458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Input Details:\n",
            "Input 0:\n",
            "  Name: serving_default_decoder_input_ids:0\n",
            "  Shape: [1 1]\n",
            "  Type: <class 'numpy.int32'>\n",
            "Input 1:\n",
            "  Name: serving_default_input_features:0\n",
            "  Shape: [   1   80 3000]\n",
            "  Type: <class 'numpy.float32'>\n",
            "\n",
            "Output Details:\n",
            "  Shape: [    1     1 51865]\n",
            "  Type: <class 'numpy.float32'>\n",
            "  Shape: [   1 1500  512]\n",
            "  Type: <class 'numpy.float32'>\n",
            "Setting decoder_input_ids with shape: (1, 1), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 2), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 3), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 4), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 5), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 6), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 7), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 8), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 9), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 10), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 11), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 12), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 13), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 14), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 15), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 16), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 17), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 18), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 19), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 20), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 21), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 22), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 23), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 24), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 25), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 26), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 27), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 28), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 29), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 30), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 31), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 32), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 33), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 34), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 35), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 36), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 37), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 38), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 39), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 40), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 41), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 42), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 43), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 44), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 45), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 46), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 47), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 48), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 49), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 50), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 51), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 52), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 53), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 54), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 55), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 56), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 57), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 58), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 59), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 60), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 61), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 62), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 63), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 64), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 65), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 66), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 67), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 68), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 69), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 70), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 71), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 72), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 73), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 74), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 75), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 76), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 77), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 78), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 79), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 80), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 81), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 82), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 83), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 84), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 85), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 86), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 87), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 88), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 89), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 90), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 91), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 92), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 93), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 94), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 95), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 96), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 97), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 98), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 99), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 100), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 101), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 102), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 103), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 104), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 105), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 106), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 107), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 108), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 109), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 110), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 111), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 112), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 113), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 114), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 115), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 116), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 117), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 118), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 119), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 120), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 121), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 122), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 123), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 124), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 125), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 126), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 127), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 128), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 129), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 130), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 131), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 132), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 133), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 134), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 135), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 136), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 137), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 138), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 139), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 140), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 141), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 142), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 143), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 144), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 145), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 146), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 147), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 148), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 149), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 150), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 151), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 152), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 153), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 154), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 155), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 156), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 157), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 158), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 159), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 160), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 161), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 162), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 163), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 164), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 165), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 166), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 167), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 168), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 169), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 170), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 171), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 172), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 173), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 174), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 175), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 176), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 177), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 178), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 179), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 180), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 181), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 182), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 183), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 184), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 185), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 186), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 187), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 188), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 189), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 190), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 191), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 192), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 193), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 194), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 195), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 196), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 197), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 198), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 199), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 200), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 201), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 202), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 203), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 204), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 205), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 206), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 207), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 208), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 209), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 210), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 211), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 212), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 213), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 214), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 215), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 216), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 217), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 218), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 219), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 220), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 221), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 222), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 223), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 224), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 225), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 226), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 227), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 228), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 229), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 230), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 231), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 232), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 233), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 234), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 235), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 236), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 237), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 238), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 239), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 240), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 241), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 242), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 243), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 244), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 245), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 246), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 247), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 248), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 249), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 250), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 251), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 252), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 253), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 254), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 255), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 256), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 257), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 258), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 259), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 260), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 261), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 262), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 263), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 264), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 265), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 266), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 267), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 268), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 269), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 270), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 271), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 272), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 273), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 274), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 275), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 276), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 277), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 278), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 279), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 280), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 281), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 282), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 283), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 284), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 285), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 286), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 287), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 288), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 289), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 290), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 291), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 292), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 293), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 294), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 295), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 296), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 297), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 298), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 299), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 300), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 301), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 302), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 303), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 304), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 305), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 306), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 307), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 308), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 309), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 310), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 311), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 312), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 313), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 314), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 315), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 316), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 317), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 318), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 319), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 320), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 321), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 322), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 323), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 324), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 325), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 326), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 327), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 328), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 329), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 330), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 331), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 332), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 333), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 334), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 335), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 336), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 337), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 338), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 339), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 340), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 341), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 342), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 343), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 344), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 345), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 346), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 347), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 348), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 349), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 350), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 351), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 352), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 353), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 354), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 355), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 356), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 357), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 358), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 359), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 360), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 361), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 362), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 363), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 364), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 365), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 366), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 367), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 368), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 369), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 370), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 371), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 372), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 373), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 374), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 375), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 376), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 377), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 378), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 379), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 380), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 381), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 382), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 383), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 384), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 385), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 386), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 387), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 388), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 389), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 390), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 391), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 392), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 393), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 394), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 395), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 396), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 397), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 398), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 399), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 400), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 401), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 402), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 403), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 404), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 405), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 406), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 407), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 408), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 409), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 410), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 411), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 412), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 413), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 414), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 415), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 416), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 417), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 418), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 419), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 420), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 421), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 422), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 423), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 424), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 425), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 426), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 427), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 428), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 429), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 430), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 431), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 432), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 433), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 434), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 435), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 436), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 437), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 438), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 439), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 440), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 441), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 442), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 443), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 444), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 445), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 446), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 447), type: int32\n",
            "Setting decoder_input_ids with shape: (1, 448), type: int32\n",
            "Arabic Transcription: الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ الرَّحْمَنِ الرَّحِيمِ مَالِكِ يَوْمِ الدِّينِ إِيَّاكَ نَعْبُدُ وَإِيَّاكَ نَسْتَعِينَ إِذْ جِنَتْ صِرَاطَ الْمُسْتَقِيمِ صِرَاطَ الَّذِينَ أَنْعَمْتَ عَلَيْهِمْْ غَيْرُ الْمُبِينَََاَا اصْطَفُواَََا اصْطَفُواَ الْمُبِينََََ لَا يَصْرَطُونََُونََََََا الْمُؤْمِنُونََََا الْمُؤْمِنُونَََا الْمُؤْمِنُونَََا الْمُؤْمِنُونََََا الْمُؤْمِنُونََا الْمُؤْمِنُونَََا الْمُؤْمِنُونَََا الْمُؤْمِنُونََا الْمُؤْمِنُونََا الْمُؤْمِنُونََا الْمُؤْمِنُونََا الْمُؤْمِنُ\n"
          ]
        }
      ]
    }
  ]
}